import requests
from bs4 import BeautifulSoup
import json

def scrape_korean_words_from_wikipedia(topics):
    words = set()
    for topic in topics:
        url = f"https://ko.wikipedia.org/wiki/{topic}"
        print(f"üåê Fetching: {url}")
        res = requests.get(url)
        if res.status_code != 200:
            print(f"‚ö†Ô∏è Failed to fetch {url}")
            continue

        soup = BeautifulSoup(res.text, "html.parser")
        for el in soup.find_all(['li', 'td', 'p']):
            text = el.get_text(strip=True)
            for token in text.split():
                if 2 <= len(token) <= 6 and all('Í∞Ä' <= ch <= 'Ìû£' for ch in token):
                    words.add(token)

    final_words = list(words)
    print(f"‚úÖ Scraped {len(final_words)} unique Korean words")
    return {word: {} for word in final_words}

if __name__ == "__main__":
    topics = [
        "ÌïúÍµ≠Ïñ¥", "Ï°∞ÏÑ†ÏãúÎåÄ", "ÌïúÎ≥µ", "Ïú†Íµê", "ÏÑ∏Ï¢ÖÎåÄÏôï", "Î∂àÍµê", "ÍµêÏú°", "ÌïúÍµ≠_Î¨∏Ìïô",
        "ÎåÄÌïúÎØºÍµ≠", "ÌïúÍµ≠_Ï†ÑÏüÅ", "ÎØºÏ£ºÌôî_Ïö¥Îèô", "ÌóåÎ≤ï", "Ï†ïÏπò_Ï†úÎèÑ", "Ïú†Ïóî",
        "Ïù∏Í≥µÏßÄÎä•", "Í≥ºÌïô_Í∏∞Ïà†", "Ï†ïÎ≥¥ÌÜµÏã†", "Î∞òÎèÑÏ≤¥", "Ïù∏ÌÑ∞ÎÑ∑", "ÏùòÌïô",
        "ÏÑúÏö∏", "ÍµêÌÜµ", "ÏùåÏãù", "ÌôòÍ≤Ω", "Í±¥Í∞ï", "Í≤ΩÏ†ú",
        "ÏòÅÌôî", "ÏùåÏïÖ", "ÏïÑÏù¥Îèå", "ÎåÄÏ§ëÎ¨∏Ìôî", "Ïù∏ÌÑ∞ÎÑ∑_Î¨∏Ìôî",
        "Ï≤†Ìïô", "ÎÖºÎ¶¨Ìïô", "Ïú§Î¶¨Ìïô", "ÏÇ¨ÌöåÌïô", "Ïã¨Î¶¨Ìïô", "Ï¢ÖÍµê"
    ]

    korean_word_dict = scrape_korean_words_from_wikipedia(topics)

    with open("./korean_word_dict.json", "w", encoding="utf-8") as f:
        json.dump(korean_word_dict, f, ensure_ascii=False, indent=2)

    print("üìÅ Saved korean_word_dict.json")
